{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a linear classification algorithm used to estimate the probability of a finite set of outcomes for a given set of features. In logistic regression, a sigmoid curve is fit to the data using maximum likelihood estimation (MLE). MLE tests different values of coefficients for each feature over multiple iterations to minimize the error between the predicted and actual values of the target variable. Once the optimal coefficient for each feature is determined through MLE (this state is referred to as 'convergence'), the logistic function uses a linear combination of the features and applies the sigmoid function (which describes the sigmoid curve) to produce a predicted probability (y^) given an observation (x).\n",
    "\n",
    "\n",
    "This notebook applies Scikit-learn's logistic regression model, which implements regularized logistic regression by default. It does so because logistic regression can be prone to overfitting, especially when a large number of features are included in analysis. Overfitting can be addressed through regularization -- in the case of logistic regression, a process in which features with large coefficients are reduced or eliminated according to a specific penalty function in order to reduce the complexity of the model. It's important to note that regularization can reduce the effects of overfitting, but it may not reduce those effects entirely. \n",
    "\n",
    "In later steps, a logistic regression model is defined, features are selected, and hyperparameters are tuned using cross-validated grid search to yield the highest performing model possible given a define set of hyperparameters. Various measures are applied to assess model performance. and These steps are explained in greater detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2480,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%run preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2481,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2482,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2483,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=5000, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 26 features after preprocessing. Recall that some features were excluded prior to applying preprocessing transformations. This isn't a huge number of features, but it may be enough to confound analysis by the model leading to lower accuracy or a less generalizable model (an overfit model) or both. At some point, adding more feature inputs in logistic regression can increase the likelihood that the model will overfit. This is why it's important to apply some degree of feature selection before model training -- reducing the number of features to only those that are most important to the problem will produce a more generalizable model.\n",
    "\n",
    "In this case,the feature selection method I've chosen to implement is `Cross-validated Recursive Feature Elimination` (Scikit-learn's RFECV) using a random forest classifier as an estimator. Recursive Feature Elimination works by fitting the model and removing the least informative feature or features and repeating until the desired/optimal number of features is reached. With cross-validation, this process is repeated k times and an optimal set of features is selected based upon a scoring algorithm (i.e. accuracy, error, or some other measure).\n",
    "\n",
    "I've chosen a `random forest classifier` (Scikit-learn's RandomForestClassifier) as an estimator for its advantages in determining feature importances. A random forest is an ensemble of decision trees. It uses random sampling of data with replacement (bagging) and and feature randomness (feature bagging) to create a forest of uncorrelated decision trees. As bagged decision trees are created, the reduction in the error function for each selected feature is calculated at each split. The greater the reduction in the error function for a given feature, the more important the feature. Evaluating feature importance across all decision trees provides a robust way of determining which subset of features is most informative of the target and which are relatively unimportant.\n",
    "\n",
    "Feature selection alone may not be enough to prevent overfitting but the hope is that in combination with model tuning a performant, generalizable model will be achieved. Feature selection steps are carried out in the code cell immediately below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c56d3_row0_col0, #T_c56d3_row0_col1, #T_c56d3_row7_col0, #T_c56d3_row7_col1, #T_c56d3_row11_col0, #T_c56d3_row11_col1, #T_c56d3_row13_col0, #T_c56d3_row13_col1, #T_c56d3_row14_col0, #T_c56d3_row14_col1, #T_c56d3_row18_col0, #T_c56d3_row18_col1, #T_c56d3_row19_col0, #T_c56d3_row19_col1, #T_c56d3_row20_col0, #T_c56d3_row20_col1, #T_c56d3_row23_col0, #T_c56d3_row23_col1, #T_c56d3_row24_col0, #T_c56d3_row24_col1, #T_c56d3_row25_col0, #T_c56d3_row25_col1, #T_c56d3_row26_col0, #T_c56d3_row26_col1 {\n",
       "  background-color: gray;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c56d3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c56d3_level0_col0\" class=\"col_heading level0 col0\" >Feature Name</th>\n",
       "      <th id=\"T_c56d3_level0_col1\" class=\"col_heading level0 col1\" >Selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c56d3_row0_col0\" class=\"data row0 col0\" >Age</td>\n",
       "      <td id=\"T_c56d3_row0_col1\" class=\"data row0 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c56d3_row1_col0\" class=\"data row1 col0\" >CabinDeck_A</td>\n",
       "      <td id=\"T_c56d3_row1_col1\" class=\"data row1 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c56d3_row2_col0\" class=\"data row2 col0\" >CabinDeck_B</td>\n",
       "      <td id=\"T_c56d3_row2_col1\" class=\"data row2 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c56d3_row3_col0\" class=\"data row3 col0\" >CabinDeck_C</td>\n",
       "      <td id=\"T_c56d3_row3_col1\" class=\"data row3 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c56d3_row4_col0\" class=\"data row4 col0\" >CabinDeck_D</td>\n",
       "      <td id=\"T_c56d3_row4_col1\" class=\"data row4 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c56d3_row5_col0\" class=\"data row5 col0\" >CabinDeck_E</td>\n",
       "      <td id=\"T_c56d3_row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c56d3_row6_col0\" class=\"data row6 col0\" >CabinDeck_F</td>\n",
       "      <td id=\"T_c56d3_row6_col1\" class=\"data row6 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c56d3_row7_col0\" class=\"data row7 col0\" >CabinDeck_G</td>\n",
       "      <td id=\"T_c56d3_row7_col1\" class=\"data row7 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c56d3_row8_col0\" class=\"data row8 col0\" >CabinDeck_T</td>\n",
       "      <td id=\"T_c56d3_row8_col1\" class=\"data row8 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c56d3_row9_col0\" class=\"data row9 col0\" >CabinLocation_Aft</td>\n",
       "      <td id=\"T_c56d3_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_c56d3_row10_col0\" class=\"data row10 col0\" >CabinLocation_Fore</td>\n",
       "      <td id=\"T_c56d3_row10_col1\" class=\"data row10 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_c56d3_row11_col0\" class=\"data row11 col0\" >CabinLocation_Mid/Aft</td>\n",
       "      <td id=\"T_c56d3_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_c56d3_row12_col0\" class=\"data row12 col0\" >CabinLocation_Mid/Fore</td>\n",
       "      <td id=\"T_c56d3_row12_col1\" class=\"data row12 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_c56d3_row13_col0\" class=\"data row13 col0\" >CabinSide_S</td>\n",
       "      <td id=\"T_c56d3_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_c56d3_row14_col0\" class=\"data row14 col0\" >CryoSleep_True</td>\n",
       "      <td id=\"T_c56d3_row14_col1\" class=\"data row14 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_c56d3_row15_col0\" class=\"data row15 col0\" >Destination_55 Cancri e</td>\n",
       "      <td id=\"T_c56d3_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_c56d3_row16_col0\" class=\"data row16 col0\" >Destination_PSO J318.5-22</td>\n",
       "      <td id=\"T_c56d3_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_c56d3_row17_col0\" class=\"data row17 col0\" >Destination_TRAPPIST-1e</td>\n",
       "      <td id=\"T_c56d3_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_c56d3_row18_col0\" class=\"data row18 col0\" >FoodCourt</td>\n",
       "      <td id=\"T_c56d3_row18_col1\" class=\"data row18 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_c56d3_row19_col0\" class=\"data row19 col0\" >HomePlanet_Earth</td>\n",
       "      <td id=\"T_c56d3_row19_col1\" class=\"data row19 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_c56d3_row20_col0\" class=\"data row20 col0\" >HomePlanet_Europa</td>\n",
       "      <td id=\"T_c56d3_row20_col1\" class=\"data row20 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_c56d3_row21_col0\" class=\"data row21 col0\" >HomePlanet_Mars</td>\n",
       "      <td id=\"T_c56d3_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_c56d3_row22_col0\" class=\"data row22 col0\" >InGroup_True</td>\n",
       "      <td id=\"T_c56d3_row22_col1\" class=\"data row22 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_c56d3_row23_col0\" class=\"data row23 col0\" >RoomService</td>\n",
       "      <td id=\"T_c56d3_row23_col1\" class=\"data row23 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_c56d3_row24_col0\" class=\"data row24 col0\" >ShoppingMall</td>\n",
       "      <td id=\"T_c56d3_row24_col1\" class=\"data row24 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_c56d3_row25_col0\" class=\"data row25 col0\" >Spa</td>\n",
       "      <td id=\"T_c56d3_row25_col1\" class=\"data row25 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c56d3_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_c56d3_row26_col0\" class=\"data row26 col0\" >VRDeck</td>\n",
       "      <td id=\"T_c56d3_row26_col1\" class=\"data row26 col1\" >True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0a5a3eb550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_features = X_test.columns\n",
    "\n",
    "estimator = RandomForestClassifier(n_jobs=-1, random_state=random_state)\n",
    "selector = RFECV(estimator, n_jobs=-1, scoring='roc_auc')\n",
    "\n",
    "X_train = selector.fit_transform(X_train, y_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "selected = selector.get_feature_names_out(input_features=input_features)\n",
    "data = {\n",
    "    'Feature Name': input_features,\n",
    "    'Selected': [(f in selected) for f in input_features],\n",
    "}\n",
    "df_selected = pd.DataFrame(data, columns=data.keys()).sort_values(by=['Feature Name']).reset_index(drop=True)\n",
    "display(df_selected.style.apply(lambda i: ['background-color: gray']*len(i) if i['Selected'] else '', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This selection method has reduced the number of features from 26 to 12. The selected features are highlighted above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Grid Search` is a model tuning method used to find the combination of hyperparameters that yields the best performing model. A hyperparameter is an input to the model that is set before the model is trained -- it is external to the model and cannot be estimated, whereas parameters are internal to the model and can be estimated (e.g. beta coefficients in logistic regression). Hyperparameters may have a significant impact on how the model learns, and therefore how the model performs.\n",
    "\n",
    "We'll implement Grid Search using Scikit-learn's GridSearchCV class. GridSearchCV trains the model over multiple iterations with various combinations of hyperparameters and tests the performance of each distinct combination using k-fold cross-validation. Once all the hyperparameter combinations have been tested, we can determine which combination yielded the best performing model.\n",
    "\n",
    " It's worth noting that sometimes fine tuning a model with grid search can lead to overfitting, so it's especially important to look for signs of overfitting when evaluating model performance. Another downside of grid search is that it is resource-intensive because all combinations of parameters are tried and - in the case of GridSearchCV - cross-validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the most important hyperparameters for logistic regression are `solver` and `penalty`. We'll tune these hyperparameters below to find the optimal solver/penalty combination and inverse of regularization strength (to prevent overfitting to the extent possible). It's important to note that not all solvers and penalties are compatible with one another.\n",
    "\n",
    "From Scikit Learn Docs:\n",
    "\n",
    ">The choice of the algorithm depends on the penalty chosen. Supported penalties by solver:\n",
    ">\n",
    ">    ‘lbfgs’ - [‘l2’, None]\n",
    ">\n",
    ">    ‘liblinear’ - [‘l1’, ‘l2’]\n",
    ">\n",
    ">    ‘newton-cg’ - [‘l2’, None]\n",
    ">\n",
    ">    ‘newton-cholesky’ - [‘l2’, None]\n",
    ">\n",
    ">    ‘sag’ - [‘l2’, None]\n",
    ">\n",
    ">    ‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, None]\n",
    "\n",
    "source: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "This solver/penalty compatibility will necessarily influence how we construct the hyperparameter combinations we'll test. I've tried to express this clearly in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-172 {color: black;}#sk-container-id-172 pre{padding: 0;}#sk-container-id-172 div.sk-toggleable {background-color: white;}#sk-container-id-172 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-172 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-172 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-172 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-172 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-172 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-172 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-172 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-172 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-172 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-172 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-172 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-172 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-172 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-172 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-172 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-172 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-172 div.sk-item {position: relative;z-index: 1;}#sk-container-id-172 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-172 div.sk-item::before, #sk-container-id-172 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-172 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-172 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-172 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-172 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-172 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-172 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-172 div.sk-label-container {text-align: center;}#sk-container-id-172 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-172 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-172\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, max_iter=5000, random_state=0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-174\" type=\"checkbox\" checked><label for=\"sk-estimator-id-174\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, max_iter=5000, random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, max_iter=5000, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 2485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [\n",
    "    {\n",
    "        'n_jobs': [None],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear'],\n",
    "        'C': [0.001, 0.01, 0.1, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "    },\n",
    "    {\n",
    "        'n_jobs': [-1],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['saga'],\n",
    "        'C': [0.001, 0.01, 0.1, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "    },\n",
    "    {\n",
    "        'n_jobs': [-1],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag'],\n",
    "        'C': [0.001, 0.01, 0.1, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "    },\n",
    "]\n",
    "\n",
    "search = GridSearchCV(\n",
    "    clf,\n",
    "    params,\n",
    "    scoring='roc_auc',\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "clf.set_params(**search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2486,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing model performance can be tricky. Certain evaluation metrics are more suited to different types of models than others. Futhermore, there can be many underlying factors that can conflate measurements and confuse interpretation of results. That being the case, it's important to use multiple metrics to assess model performance, and to chose the metrics best suited to the type of model employed.\n",
    "\n",
    "The `accuracy` score for the model is a simple calculation of the number of correct predictions out of the total number of predictions. It tends to be a good metric of model performance when data is balanced. But assessing a model by the proportion of correct predictions alone can be misleading. Any model could be subject to the 'Accurary Paradox'. The Accuracy Paradox describes a phenomenon in which a model with higher accuracy has less predictive power than a model with lower accuracy. This can be caused by imbalanced data and/or overfitting, among other causes. Therefore, it's also important to consider other factors. We can also assess a model by its `precision` and `recall`. Precision is a measure of the accuracy of the model's positive predictions that penalizes false-positives; and recall measures what proportion of those postive cases the model actually identified as positive -- it penalizes false-negatives. These are often considered together as the `F1` score, which is the harmonic mean of precision and recall.\n",
    "\n",
    "Another reliable way to assess the performance of a classification model is to calculate `ROC AUC`. The ROC (Receiver Operating Characteristics) Curve plots the relationship between the true-positive rate (y-axis) and the false-positive rate (x-axis) at various classification thresholds. The Area Under Curve is a measure of class separability -- it tells us how well the model performs at distinguishing between classes. A ROC AUC score of 0.5 (lowest score) means the model has very little or no ability to distinguish between classes; and a score of 1.0 (highest score) means the model performs perfectly at distinguishing between classes. ROC AUC is a good metric when data is imbalanced.\n",
    "\n",
    "Here's a summary of how these various metrics are calculated:\n",
    "\n",
    "- **Accuracy:**\n",
    "    - Number of correct predictions out of the total number of predictions\n",
    "    - Beware of the accuracy paradox\n",
    "    - A poor metric for imbalanced data\n",
    "    - (true-positive + true-negative) / total observations\n",
    ">\n",
    "- **Precision:**\n",
    "    - Accuracy of positive predictions.\n",
    "    - Prefer when minimizing false-positives is the priority\n",
    "    - true-positive / (true-positive + false-postive)\n",
    ">\n",
    "- **Recall:**\n",
    "    - Proportion of positive cases the model actually identified as positive\n",
    "    - Prefer when minimizing false-negatives is the priority\n",
    "    - true-positive / (true-positive + false-negative)\n",
    ">\n",
    "- **F1:**\n",
    "    - Harmonic mean of precision and recall\n",
    "    - Prefer when minimizing all false predictions is the priority\n",
    "    - 2 * precision * recall / (precision + recall)\n",
    ">\n",
    "- **ROC AUC:**\n",
    "    - A measure of class separability\n",
    "    - Measures how well the model performs at distinguishing between classes\n",
    "    - A good metric for imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying these metrics, it can help to get a sense of the distribution of the model's predictions. A confusion matrix can help vizualize the distribution. Scikit-learn's confusion_matrix function is used below to report the distribution of true-positive, false-positive, false-negative, and true-negative predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f0a5374aef0>"
      ]
     },
     "execution_count": 2487,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=['True', 'False'], cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these figures and the formulas above, we could calculate each metric manually; but let's just use Scikit-learn's convenient classification_report function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Transported (False)     0.8437    0.7206    0.7773      1303\n",
      " Transported (True)     0.7565    0.8667    0.8079      1305\n",
      "\n",
      "           accuracy                         0.7937      2608\n",
      "          macro avg     0.8001    0.7937    0.7926      2608\n",
      "       weighted avg     0.8001    0.7937    0.7926      2608\n",
      "\n",
      "ROC AUC: 0.8817\n"
     ]
    }
   ],
   "source": [
    "clf_report = classification_report(y_test, y_pred, target_names=['Transported (False)', 'Transported (True)'], digits=4)\n",
    "print(clf_report)\n",
    "\n",
    "roc_auc_score = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "print(f\"ROC AUC: {roc_auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`K-Fold Cross-validation` can provide even more confidence in the above metrics. K-fold cross-validation works by dividiing the dataset into 'k' number of subsets (folds), and then trains and tests the model over 'k' rounds. During each round, the model is trained on all but one subset (k-1), and the remaining subset is used as a test set to produce an accuracy score for that round. We can get a good sense of model performance by evaluating the average accuracy and ROC AUC accross all cross-validations performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold CV Accuracies: 0.7975 (train) | 0.7983 (test)\n",
      "K-fold CV ROC AUCs: 0.8822 (train) | 0.8775 (test)\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = cross_val_score(clf, X=X_train, y=y_train, scoring='accuracy')\n",
    "train_roc_auc = cross_val_score(clf, X=X_train, y=y_train, scoring='roc_auc')\n",
    "\n",
    "test_accuracy = cross_val_score(clf, X=X_test, y=y_test, scoring='accuracy')\n",
    "test_roc_auc = cross_val_score(clf, X=X_test, y=y_test, scoring='roc_auc')\n",
    "\n",
    "accuracies = f\"K-fold CV Accuracies: {train_accuracy.mean():.4f} (train) | {test_accuracy.mean():.4f} (test)\"\n",
    "roc_aucs = f\"K-fold CV ROC AUCs: {train_roc_auc.mean():.4f} (train) | {test_roc_auc.mean():.4f} (test)\"\n",
    "print(f\"{accuracies}\\n{roc_aucs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the model performs well at distinguishing between classes with a ROC AUC score of about 0.88 for both the training and test sets. The accuracy score is roughly 80% for both the training and test sets. Because accuracy and ROC AUC scores are very similar between test and training sets, we can be reasonably confident that the model is not overfitting. The F1 score is very similar to the accuracy score at nearly 80%. The model is better at predicting true-negatives than true-positives. The false-positive rate is higher than the false-negative rate as indicated by the precision and recall scores respectively (you can see it plainly in the confusion matrix as well). There might be more useful features that can be engineered from the dataset, but those really should be supported by strong hypotheses or domain knowledge. It might be the case that a different type of model might be more suited to the problem, but the model performs well nonetheless."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-ml",
   "language": "python",
   "name": "ds-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
