{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    RobustScaler,\n",
    "    LabelEncoder, \n",
    "    OneHotEncoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values before imputation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet      201\n",
       "CryoSleep       217\n",
       "Cabin           199\n",
       "Destination     182\n",
       "Age             179\n",
       "VIP             203\n",
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "Name            200\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 'PassengerId' into 'GroupdId' and 'PersonId', and split 'Name' into 'FirstName' and 'LastName'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 'PassengerId' into 'GroupId', 'PersonId'\n",
    "df[['GroupId', 'PersonId']] = df['PassengerId'].str.split('_', expand=True)\n",
    "\n",
    "# split 'Name' into 'FirstName' and 'LastName'\n",
    "df[['FirstName', 'LastName']] = df['Name'].str.split(' ', n=1, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing 'LastName' values according to the following insights:\n",
    "\n",
    "- Passengers sharing a group Id often share a common last name.\n",
    "\n",
    "- Passengers sharing a cabin often share a last name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing 'LastName'...\n",
    "\n",
    "# by 'GroupId'\n",
    "\n",
    "# identify passengers traveling in a group\n",
    "sharedgroup_idx = df[df['GroupId'].duplicated(keep=False)].index\n",
    "\n",
    "# identify passengers traveling in a group with missing 'LastName'\n",
    "targeted_idx = df[(df.index.isin(sharedgroup_idx)) & (df['LastName'].isna())].index\n",
    "\n",
    "# identify passengers traveling in a group with known 'LastName(s)'\n",
    "source_idx = df[(df.index.isin(sharedgroup_idx)) & (df['LastName'].notna())].index\n",
    "\n",
    "# fill missing\n",
    "df.loc[targeted_idx, 'LastName'] = df.iloc[targeted_idx, :]['GroupId'].map(\n",
    "    lambda x: df.iloc[source_idx, :][df.loc[source_idx, 'GroupId'] == x]['LastName'].mode().max()\n",
    ")\n",
    "\n",
    "# by 'Cabin'\n",
    "\n",
    "# identify passengers sharing a cabin\n",
    "sharedcabin_idx = df[df['Cabin'].duplicated(keep=False)].index\n",
    "\n",
    "# identify passengers sharing a cabin with missing 'LastName'\n",
    "targeted_idx = df[(df.index.isin(sharedcabin_idx)) & (df['LastName'].isna())].index\n",
    "\n",
    "# identify passengers sharing a cabin with known 'LastName(s)'\n",
    "source_idx = df[(df.index.isin(sharedcabin_idx)) & (df['LastName'].notna())].index\n",
    "\n",
    "# fill missing\n",
    "df.loc[targeted_idx, 'LastName'] = df.iloc[targeted_idx, :]['Cabin'].map(\n",
    "    lambda x: df.iloc[source_idx, :][df.loc[source_idx, 'Cabin'] == x]['LastName'].mode().max()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing 'Cabin' values according to the following insight:\n",
    "\n",
    "- Passengers sharing a group Id often share the same cabin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing 'Cabin'...\n",
    "\n",
    "# by 'GroupId'\n",
    "\n",
    "# identify passengers traveling in a group\n",
    "sharedgroup_idx = df[df['GroupId'].duplicated(keep=False)].index\n",
    "\n",
    "# identify passengers traveling in a group with missing 'Cabin'\n",
    "targeted_idx = df[(df.index.isin(sharedgroup_idx)) & (df['Cabin'].isna())].index\n",
    "\n",
    "# identify passengers traveling in a group with known 'Cabin(s)'\n",
    "source_idx = df[(df.index.isin(sharedgroup_idx)) & (df['Cabin'].notna())].index\n",
    "\n",
    "# fill missing\n",
    "df.loc[targeted_idx, 'Cabin'] = df.iloc[targeted_idx, :]['GroupId'].map(\n",
    "    lambda x: df.iloc[source_idx, :][df.loc[source_idx, 'GroupId'] == x]['Cabin'].mode().max()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split 'Cabin' into 'CabinDeck', 'CabinNumber', and 'CabinSide'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split 'Cabin'\n",
    "df[['CabinDeck', 'CabinNumber', 'CabinSide']] = df['Cabin'].str.split('/', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing 'HomePlanet' values according to the following insights:\n",
    "\n",
    "- Passengers with a cabin on decks \"A\", \"B\", \"C\" and \"T\" are from Europa. Passengers with a cabin on deck \"G\" are from Earth.\"\n",
    "\n",
    "- Passengers sharing a group Id always come from the same home planet.\n",
    "\n",
    "- Passengers sharing a last name always com from the same home planet.\n",
    "\n",
    "- Passengers sharing a cabin always com from the same home planet.\n",
    "\n",
    "- Passengers traveling to \"PSO J318.5-22\" almost always come from Earth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing 'HomePlanet'...\n",
    "\n",
    "# by 'CabinDeck'\n",
    "\n",
    "# identify passengers with missing 'HomePlanet' and 'CabinDecks' of 'A', 'B', 'C', 'G', or 'T'\n",
    "targeted_idx = df[(df['HomePlanet'].isna()) & (df['CabinDeck'].isin(['A', 'B', 'C', 'G', 'T']))].index\n",
    "\n",
    "# fill missing\n",
    "df.loc[targeted_idx, 'HomePlanet'] = df.iloc[targeted_idx, :]['CabinDeck'].map(\n",
    "    lambda x: 'Earth' if x == 'G' else 'Europa'\n",
    ")\n",
    "\n",
    "# by 'GroupId'\n",
    "\n",
    "# identify passengers traveling in a group\n",
    "sharedgroup_idx = df[df['GroupId'].duplicated(keep=False)].index\n",
    "\n",
    "# identify passengers traveling in a group with missing 'HomePlanet'\n",
    "targeted_idx = df[(df.index.isin(sharedgroup_idx)) & (df['HomePlanet'].isna())].index\n",
    "\n",
    "# identify passengers traveling in a group with known 'Homeplanet'\n",
    "source_idx = df[(df.index.isin(sharedgroup_idx)) & (df['HomePlanet'].notna())].index\n",
    "\n",
    "# fill missing\n",
    "df.loc[targeted_idx, 'HomePlanet'] = df.iloc[targeted_idx, :]['GroupId'].map(\n",
    "    lambda x: df.iloc[source_idx, :][df.loc[source_idx, 'GroupId'] == x]['HomePlanet'].mode().max()\n",
    ")\n",
    "\n",
    "# by 'LastName'\n",
    "\n",
    "# identify passengers sharing a last name\n",
    "sharedlastname_idx = df[(df['LastName'].duplicated(keep=False)) & (df['LastName'].notna())].index\n",
    "\n",
    "# identify passengers sharing a last name with missing 'HomePlanet'\n",
    "targeted_idx = df[(df.index.isin(sharedlastname_idx)) & (df['HomePlanet'].isna())].index\n",
    "\n",
    "# identify passengers sharing a last name with known 'HomePlanet'\n",
    "source_idx = df[(df.index.isin(sharedlastname_idx)) & (df['HomePlanet'].notna())].index\n",
    "\n",
    "# fill missing\n",
    "df.loc[targeted_idx, 'HomePlanet'] = df.iloc[targeted_idx, :]['LastName'].map(\n",
    "    lambda x: df.iloc[source_idx, :][df.loc[source_idx, 'LastName'] == x]['HomePlanet'].mode().max()\n",
    ")\n",
    "\n",
    "# by 'Cabin'\n",
    "\n",
    "# identify passengers sharing a cabin\n",
    "sharedcabin_idx = df[(df['Cabin'].duplicated(keep=False)) & (df['Cabin'].notna())].index\n",
    "\n",
    "# identify passengers sharing a cabin with missing 'HomePlanet'\n",
    "targeted_idx = df[(df.index.isin(sharedcabin_idx)) & (df['HomePlanet'].isna())].index\n",
    "\n",
    "# identify passengers sharing a cabin with known 'HomePlanet'\n",
    "source_idx = df[(df.index.isin(sharedcabin_idx)) & (df['HomePlanet'].notna())].index\n",
    "\n",
    "# fill missing\n",
    "df.loc[targeted_idx, 'HomePlanet'] = df.iloc[targeted_idx, :]['Cabin'].map(\n",
    "    lambda x: df.iloc[source_idx, :][df.loc[source_idx, 'Cabin'] == x]['HomePlanet'].mode().max()\n",
    ")\n",
    "\n",
    "# by 'Destination'\n",
    "\n",
    "# identify passengers with missing 'HomePlanet' and 'Destination' of 'PSO J318.5-22'\n",
    "targeted_idx = df[(df['HomePlanet'].isna()) & (df['Destination'] == 'PSO J318.5-22')].index\n",
    "\n",
    "# fill missing\n",
    "df.loc[targeted_idx, 'HomePlanet'] = 'Earth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing 'CabinDeck' values according to the following insight:\n",
    "\n",
    "- ...for missing 'CabinDeck' values, we can impute the mode by 'HomePlanet'. It's not perfect, but it's far better than imputing the mode for all cabin decks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing 'CabinDeck'\n",
    "\n",
    "# by 'HomePlanet'\n",
    "\n",
    "# imput mode for passengers from 'Earth'\n",
    "cd_mode_earth = df[(df['CabinDeck'].notna()) & (df['HomePlanet'] == 'Earth')]['CabinDeck'].mode()[0]\n",
    "targeted_idx = df[(df['CabinDeck'].isna()) & (df['HomePlanet'] == 'Earth')].index\n",
    "df.loc[targeted_idx, 'CabinDeck'] = cd_mode_earth\n",
    "\n",
    "# imput mode for passengers from 'Europa'\n",
    "cd_mode_europa = df[(df['CabinDeck'].notna()) & (df['HomePlanet'] == 'Europa')]['CabinDeck'].mode()[0]\n",
    "targeted_idx = df[(df['CabinDeck'].isna()) & (df['HomePlanet'] == 'Europa')].index\n",
    "df.loc[targeted_idx, 'CabinDeck'] = cd_mode_europa\n",
    "\n",
    "# imput mode for passengers from 'Mars'\n",
    "cd_mode_mars = df[(df['CabinDeck'].notna()) & (df['HomePlanet'] == 'Mars')]['CabinDeck'].mode()[0]\n",
    "targeted_idx = df[(df['CabinDeck'].isna()) & (df['HomePlanet'] == 'Mars')].index\n",
    "df.loc[targeted_idx, 'CabinDeck'] = cd_mode_mars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing amenities values according to the following insights:\n",
    "\n",
    "- Passengers in cryosleep did not purchase amenities.\n",
    "\n",
    "- Passengers the age of roughly 12 years old and younger did not purchase amenities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing 'amenities'...\n",
    "\n",
    "for a in amenities:\n",
    "    # by 'CryoSleep'\n",
    "    targeted_idx = df[(df['CryoSleep'] == True) & (df[a].isna())].index\n",
    "    df.loc[targeted_idx, a] = 0.0\n",
    "    \n",
    "    # by 'Age'\n",
    "    targeted_idx = df[(df['Age'] <= 12) & (df[a].isna())].index\n",
    "    df.loc[targeted_idx, a] =  0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing 'CryoSleep' values according to the following insights:\n",
    "\n",
    "- Passengers who purchased amenities were not in cyrosleep.\n",
    "\n",
    "- Adult passengers (age 18 and older) who did not purchase amenities were in cryosleep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing 'CryoSleep'...\n",
    "\n",
    "# by 'amenities'\n",
    "targeted_idx = df[df['CryoSleep'].isna()].index\n",
    "df.loc[targeted_idx, 'CryoSleep'] = df.iloc[targeted_idx, :].apply(\n",
    "    lambda i: False if i[amenities].sum() > 0 else i['CryoSleep'], axis=1\n",
    ")\n",
    "\n",
    "# by 'Age'\n",
    "targeted_idx = df[(df['CryoSleep'].isna()) & (df['Age'] >= 18)].index\n",
    "df.loc[targeted_idx, 'CryoSleep'] = df.iloc[targeted_idx, :].apply(\n",
    "    lambda i: True if i[amenities].sum() == 0 else i['CryoSleep'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 'InGroup' feature to indicate whether a passenger belongs to a group. This feature proxies for 'PersonId'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InGroup'] = df['GroupId'].duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 'CabinLocation' feature to indicate a the location of a cabin on a given deck. This feature proxies for 'CabinNumber'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall 'CabinNumber' is cast to an integer to make binning easier...\n",
    "df['CabinNumber'] = df['CabinNumber'].map(lambda x: int(x) if pd.notna(x) else x)\n",
    "\n",
    "# binned according to EDA insight...\n",
    "df['CabinLocation'] = df['CabinNumber'].map(\n",
    "    lambda x: (\n",
    "        'Fore' if x <= 375 else 'Mid/Fore' if x > 375 and x <= 750 else 'Mid/Aft' if x > 750 and x <= 1125 else 'Aft'\n",
    "    ) if pd.notna(x) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values after imputation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "HomePlanet         8\n",
       "CryoSleep         33\n",
       "Cabin             99\n",
       "Destination      182\n",
       "Age              179\n",
       "VIP              203\n",
       "RoomService      107\n",
       "FoodCourt        106\n",
       "ShoppingMall     103\n",
       "Spa              114\n",
       "VRDeck           107\n",
       "Name             200\n",
       "Transported        0\n",
       "GroupId            0\n",
       "PersonId           0\n",
       "FirstName        200\n",
       "LastName         104\n",
       "CabinDeck          0\n",
       "CabinNumber       99\n",
       "CabinSide         99\n",
       "InGroup            0\n",
       "CabinLocation     99\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that missing values have been imputed according to EDA insights to the extent possible, input features and the target can be transformed and the data split into test and training sets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\n",
    "    'HomePlanet',\n",
    "    'CabinDeck',\n",
    "    'CabinSide',\n",
    "    'CryoSleep',\n",
    "    'Destination',\n",
    "    'CabinLocation',\n",
    "    'InGroup',\n",
    "]\n",
    "\n",
    "num_features = [\n",
    "    'Age',\n",
    "    *amenities,\n",
    "]\n",
    "\n",
    "cat_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(drop='if_binary', handle_unknown='ignore', sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', KNNImputer()),\n",
    "        ('scaler', RobustScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transformers = [\n",
    "    ('cat_transformer', cat_transformer, cat_features),\n",
    "    ('num_transformer', num_transformer, num_features),\n",
    "]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformers, \n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "preprocessor.set_output(transform='pandas')\n",
    "\n",
    "features = [\n",
    "    *cat_features,\n",
    "    *num_features,\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df['Transported']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train, y_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage the data has been transformed and split into training and test sets. To review model training steps, see individual model notebooks (e.g. `logisticregression.ipynb`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-ml",
   "language": "python",
   "name": "ds-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
